{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80634042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b952944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractured(source, min_points=1, max_points=4, min_radius=3, max_radius=6, sphere_chance=0.75):\n",
    "    fractured = source.copy()\n",
    "    points = np.random.randint(min_points, max_points+1)\n",
    "    idxs = np.argwhere(fractured == 1)\n",
    "    centers = idxs[np.random.choice(len(idxs), points, False)]\n",
    "    \n",
    "    for x,y,z in centers:\n",
    "        r = np.random.randint(min_radius, max_radius+1)\n",
    "        xmin, xmax = max(0, x-r), x+r\n",
    "        ymin, ymax = max(0, y-r), y+r\n",
    "        zmin, zmax = max(0, z-r), z+r\n",
    "        sphere = np.ones_like(fractured)\n",
    "        sphere[xmin:xmax, ymin:ymax, zmin:zmax] = 0\n",
    "        # sphere or cube\n",
    "        if np.random.rand() < sphere_chance:\n",
    "            idxs = np.argwhere(sphere == 0)\n",
    "            idxs_remove = np.sqrt((idxs[:,0] - x)**2 + (idxs[:,1] - y)**2 + (idxs[:,2] - z)**2)\n",
    "            idxs_remove = idxs[idxs_remove > r]\n",
    "            sphere[idxs_remove[:,0], idxs_remove[:,1], idxs_remove[:,2]] = 1\n",
    "            \n",
    "        fractured *= sphere\n",
    "    \n",
    "    return fractured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40e0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_to_point_cloud(vol):\n",
    "    \"\"\" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n",
    "        return Nx3 numpy array.\n",
    "    \"\"\"\n",
    "    vsize = vol.shape[0]\n",
    "    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n",
    "    points = []\n",
    "    for a in range(vsize):\n",
    "        for b in range(vsize):\n",
    "            for c in range(vsize):\n",
    "                if vol[a,b,c] == 1:\n",
    "                    points.append(np.array([a,b,c]))\n",
    "    if len(points) == 0:\n",
    "        return np.zeros((0,3))\n",
    "    points = np.vstack(points)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469d43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(vol, s=10, c=(105,127,155), show_grid=False):\n",
    "    if vol.dtype != np.bool:\n",
    "        vol = vol > 0\n",
    "\n",
    "    pc = volume_to_point_cloud(vol)\n",
    "    plot3d(pc, s, c, show_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e97ef8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./modelnet10.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "data = np.load('./modelnet10.npy').item()['test']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9062af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./modelnet10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1091db69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./custom_arq_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f1fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting binvox\n",
      "  Downloading binvox-0.1.5.tar.gz (4.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\brebe\\anaconda3\\lib\\site-packages (from binvox) (1.21.5)\n",
      "Building wheels for collected packages: binvox\n",
      "  Building wheel for binvox (setup.py): started\n",
      "  Building wheel for binvox (setup.py): finished with status 'done'\n",
      "  Created wheel for binvox: filename=binvox-0.1.5-py3-none-any.whl size=5174 sha256=157c640d70fe12f25c64a2e79bdbd163c3dcc4fb0cdfabe02cecfb085eb0ccb8\n",
      "  Stored in directory: c:\\users\\brebe\\appdata\\local\\pip\\cache\\wheels\\90\\60\\92\\4a1371a804a6a54bf33cd2be960651cf09a001b1e7a209077c\n",
      "Successfully built binvox\n",
      "Installing collected packages: binvox\n",
      "Successfully installed binvox-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install binvox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b199f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e76add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
      "Counter({'chair': 889, 'sofa': 680, 'bed': 515, 'monitor': 465, 'table': 392, 'toilet': 344, 'desk': 200, 'dresser': 200, 'night_stand': 200, 'bathtub': 106})\n"
     ]
    }
   ],
   "source": [
    "path = './ModelNet/ModelNet10'\n",
    "labels = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "files = [os.path.join(path,l,'train',ll) for l in labels\n",
    "         for ll in os.listdir(os.path.join(path, l, 'train'))\n",
    "         if ll[-4:] == '.off']\n",
    "\n",
    "print(labels)\n",
    "print(Counter([f.split('./ModelNet/ModelNet10')[1].split('\\\\')[1] for f in files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "860471c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting: ./ModelNet/ModelNet10\\sofa\\train\\sofa_0177.off\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m voxels \u001b[38;5;241m=\u001b[39m voxels_from_file(file, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlotting:\u001b[39m\u001b[38;5;124m'\u001b[39m, file)\n\u001b[1;32m---> 37\u001b[0m \u001b[43mplot_vol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mplot_vol\u001b[1;34m(vol, s, c, show_grid)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_vol\u001b[39m(vol, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, c\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m105\u001b[39m,\u001b[38;5;241m127\u001b[39m,\u001b[38;5;241m155\u001b[39m), show_grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool:\n\u001b[0;32m      3\u001b[0m         vol \u001b[38;5;241m=\u001b[39m vol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m     pc \u001b[38;5;241m=\u001b[39m volume_to_point_cloud(vol)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8880883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a61ac8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = zf.ZipFile(\"./ModelNet/ModelNet40.zip\", 'r')\n",
    "files.extractall('./ModelNet/')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cb4fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = zf.ZipFile(\"./ModelNet/ModelNet10.zip\", 'r')\n",
    "files.extractall('./ModelNet/')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "580672d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7724db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def multithreading(func, args, workers):\n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        res = executor.map(func, args)\n",
    "    return list(res)\n",
    "\n",
    "get_label = lambda x: x.split('ModelNet')[1][3:].split('/')[0]\n",
    "\n",
    "def get_voxels(files, voxsize):\n",
    "    data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n",
    "    labels = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        res = voxels_from_file(file, voxsize)\n",
    "        if res[0] == 1:\n",
    "            labels.append(get_label(file))\n",
    "            data = np.vstack([data, res[1].reshape((1, *res[1].shape))])\n",
    "        else:\n",
    "            errors.append(file)\n",
    "\n",
    "    return labels, data, errors\n",
    "\n",
    "get_voxels_parallel = lambda x: get_voxels(*x)\n",
    "\n",
    "def convert_all(path, voxsize):\n",
    "    out_file = os.path.join(path, 'voxels.npy')\n",
    "    labels = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    train_files = [os.path.join(path,l,'train',ll) for l in labels\n",
    "                   for ll in os.listdir(os.path.join(path, l, 'train'))\n",
    "                   if ll[-4:] == '.off']\n",
    "    test_files = [os.path.join(path,l,'test',ll) for l in labels\n",
    "                   for ll in os.listdir(os.path.join(path, l, 'test'))\n",
    "                   if ll[-4:] == '.off']\n",
    "\n",
    "    print(f'train: {len(train_files)}, test: {len(test_files)}')\n",
    "    \n",
    "    n_cpu = multiprocessing.cpu_count()\n",
    "    output = {}\n",
    "    \n",
    "    for data_files, data_name in zip([train_files, test_files], ['train', 'test']):\n",
    "        t0 = time()\n",
    "        print(f'Launching {n_cpu} threads for {data_name} set...', end='')\n",
    "        thread_size = math.ceil(len(data_files) / n_cpu)\n",
    "        args = [(data_files[i*thread_size:(i+1)*thread_size], voxsize) for i in range(n_cpu)]\n",
    "        res = multithreading(get_voxels_parallel, args, n_cpu)\n",
    "        labels = []\n",
    "        data = np.ndarray((0, *[voxsize]*3), dtype=np.bool)\n",
    "        errors = []\n",
    "\n",
    "        for l, d, e in res:\n",
    "            labels += l\n",
    "            data = np.vstack([data, d])\n",
    "            errors += e\n",
    "            \n",
    "        output[data_name] = {'labels': labels, 'data': data, 'errors': errors}\n",
    "        \n",
    "        print('(%.2fs)' % (time() - t0))\n",
    "    \n",
    "    np.save(out_file, output)    \n",
    "    print('\\nSaved on: %s (%.2fM)' % (out_file, os.path.getsize(out_file) / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43e32d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3991, test: 908\n",
      "Launching 16 threads for train set..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brebe\\AppData\\Local\\Temp\\ipykernel_31536\\4063895973.py:12: DeprecationWarning:\n",
      "\n",
      "`np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "C:\\Users\\brebe\\AppData\\Local\\Temp\\ipykernel_31536\\4063895973.py:50: DeprecationWarning:\n",
      "\n",
      "`np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43.73s)\n",
      "Launching 16 threads for test set...(11.67s)\n",
      "\n",
      "Saved on: ./ModelNet/ModelNet10/voxels.npy (0.27M)\n"
     ]
    }
   ],
   "source": [
    "convert_all('./ModelNet/ModelNet10/', voxsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5deda001",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ModelNet/ModelNet10/voxels.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:440\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode)\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py:743\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    744\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "data = np.load('./ModelNet/ModelNet10/voxels.npy').item()['test']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b5978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
